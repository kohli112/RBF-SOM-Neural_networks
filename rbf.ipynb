{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HR8WfoTMyhNT"
   },
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-Th6rfaBM-L"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "random.seed(1)\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WKS7W5a3vJbG"
   },
   "source": [
    "Making the dataset. I randomly take some values between 0, 20 and store them using a set to ensure unique data points. Then I make our final data set which includes the appended labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FrMLmLBWCE-8",
    "outputId": "1724b395-f414-4368-8ded-0072f0e7a460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441\n"
     ]
    }
   ],
   "source": [
    "data = set()\n",
    "for i in range(21):\n",
    "  for j in range(21):\n",
    "    x = round(-2 +  i*0.2, 2)\n",
    "    y = round(-2 + j*0.2, 2)\n",
    "    data.add((x,y))\n",
    "data_list = list(data)\n",
    "print(len(data_list))\n",
    "data_array = np.array(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h1lsD3U1Ouo5"
   },
   "outputs": [],
   "source": [
    "#Mapping\n",
    "data_mapped = []\n",
    "for point in data_list:\n",
    "    if (point[0]**2) + (point[1]**2) <= 1:\n",
    "        data_mapped.append([point[0], point[1], 1])\n",
    "    else:\n",
    "        data_mapped.append([point[0], point[1], -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VTWSJP0owzoR"
   },
   "source": [
    "In the next block, I shuffle my data and then divide it into 80-20 train test split and then take out the labels to use only data for the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5A4Csf-QnCi"
   },
   "outputs": [],
   "source": [
    "inp = random.sample(data_mapped, len(data_mapped))\n",
    "final_data = np.array(inp)\n",
    "train_size = int(0.8 * len(inp))\n",
    "train_set = final_data[:train_size]\n",
    "test_set = final_data[train_size:]\n",
    "X_train = train_set[:, :2]\n",
    "y_train = train_set[:, 2:]\n",
    "X_test = test_set[:, :2]\n",
    "y_test = test_set[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0kkGZlWIxZ0Y"
   },
   "source": [
    "This next block defines all the required functions. They include the kernel gaussian function calculation, getting interpolation matrix(Weight matrix), getting prediction values, MSE calculation and accuracy calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFtfsokWWf0D"
   },
   "outputs": [],
   "source": [
    "def gaussian_fn(distance, sig):\n",
    "    return np.exp(-(distance)**2 / (2* (sig**2)))\n",
    "\n",
    "def mse(actual, pred):\n",
    "    summation = 0\n",
    "    for i in range(len(pred)):\n",
    "        diff = actual[i] - pred[i]\n",
    "        squared_diff = diff**2\n",
    "        summation = summation + squared_diff\n",
    "    error = summation/len(pred)\n",
    "    return error\n",
    "\n",
    "def calcWeight(X_train, X_cent, sigma):\n",
    "  G = np.zeros((len(X_train), len(X_cent)))\n",
    "  for i in range(len(X_train)):\n",
    "    for j in range(len(X_cent)):\n",
    "      dist = np.linalg.norm(X_train[i] - X_cent[j])\n",
    "      G[i][j] = gaussian_fn(dist, sigma)\n",
    "  G1 = np.linalg.pinv(G)\n",
    "  W = G1.dot(y_train)\n",
    "  y_pred = G.dot(W)\n",
    "  return y_pred, W\n",
    "\n",
    "def pred(X_test, X_t, sigma, W):\n",
    "  g1 = np.zeros((len(X_test), len(X_t)))\n",
    "  for i in range(len(X_test)):\n",
    "    for j in range(len(X_t)):\n",
    "      dist = np.linalg.norm(X_test[i] - X_t[j])\n",
    "      g1[i][j] = gaussian_fn(dist, sigma)  \n",
    "  y_pred_test = g1.dot(W)\n",
    "  return y_pred_test\n",
    "\n",
    "def acc(y_train, y_pred):\n",
    "  acc=np.mean(y_train==np.sign(y_pred))\n",
    "  return round(acc*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DW-23unwxzZY"
   },
   "source": [
    "The code blocks below use the functions defined to get the accuracy and error for the different cases as required in the assignment.\n",
    "The training and test accuracies for all the runs can be seen in the output blocks for each case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AabP3ajGbo_i"
   },
   "source": [
    "#1. Using all the points in the training set as Centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VbmuGNk1X3y8",
    "outputId": "fc8c6f31-ece3-4c07-eccd-8f36ee75eb74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Sigma =  0.01\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  96.63\n",
      "Train Error:  1.3562748837455712e-30\n",
      "Test Error:  1.0\n",
      "For Sigma =  0.03\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  96.63\n",
      "Train Error:  2.292980676570171e-29\n",
      "Test Error:  0.9999999988304806\n",
      "For Sigma =  0.05\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  96.63\n",
      "Train Error:  5.36851221152538e-30\n",
      "Test Error:  0.9982452499613711\n",
      "For Sigma =  0.1\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  96.63\n",
      "Train Error:  3.659757131048865e-30\n",
      "Test Error:  0.5084299006895513\n",
      "For Sigma =  0.15\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  95.51\n",
      "Train Error:  6.162065382429081e-30\n",
      "Test Error:  0.19056038449875398\n",
      "For Sigma =  0.2\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  92.13\n",
      "Train Error:  2.1985075097545227e-28\n",
      "Test Error:  0.23601981221827836\n",
      "For Sigma =  0.25\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  91.01\n",
      "Train Error:  5.472168944169246e-26\n",
      "Test Error:  0.4633668299771678\n",
      "For Sigma =  0.5\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  67.42\n",
      "Train Error:  3.31927434275721e-09\n",
      "Test Error:  2189.170754624916\n",
      "For Sigma =  0.75\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  87.64\n",
      "Train Error:  0.019766957795747494\n",
      "Test Error:  8.006063669229977\n",
      "For Sigma =  1\n",
      "Train Accuracy:  99.43\n",
      "Test Accuracy:  96.63\n",
      "Train Error:  0.03555256076899902\n",
      "Test Error:  0.21322478174252876\n",
      "For Sigma =  3\n",
      "Train Accuracy:  99.43\n",
      "Test Accuracy:  97.75\n",
      "Train Error:  0.09850951582153687\n",
      "Test Error:  0.1219533120093637\n",
      "For Sigma =  5\n",
      "Train Accuracy:  97.16\n",
      "Test Accuracy:  97.75\n",
      "Train Error:  0.11332492598057797\n",
      "Test Error:  0.12549531895237626\n",
      "For Sigma =  7\n",
      "Train Accuracy:  97.44\n",
      "Test Accuracy:  97.75\n",
      "Train Error:  0.1239298180370993\n",
      "Test Error:  0.12358933047928301\n",
      "For Sigma =  10\n",
      "Train Accuracy:  97.44\n",
      "Test Accuracy:  97.75\n",
      "Train Error:  0.12453988847449761\n",
      "Test Error:  0.1227232079241383\n",
      "For Sigma =  12\n",
      "Train Accuracy:  99.72\n",
      "Test Accuracy:  97.75\n",
      "Train Error:  0.1300897334109653\n",
      "Test Error:  0.12931194265237014\n",
      "For Sigma =  15\n",
      "Train Accuracy:  98.3\n",
      "Test Accuracy:  98.88\n",
      "Train Error:  0.19611170824688545\n",
      "Test Error:  0.17511157229199625\n",
      "For Sigma =  17\n",
      "Train Accuracy:  98.3\n",
      "Test Accuracy:  98.88\n",
      "Train Error:  0.19634673055846655\n",
      "Test Error:  0.17537421481377483\n",
      "For Sigma =  20\n",
      "Train Accuracy:  98.3\n",
      "Test Accuracy:  98.88\n",
      "Train Error:  0.19657904040811694\n",
      "Test Error:  0.17546024056821224\n",
      "For Sigma =  25\n",
      "Train Accuracy:  98.58\n",
      "Test Accuracy:  98.88\n",
      "Train Error:  0.1969381147094034\n",
      "Test Error:  0.17462419429362303\n",
      "For Sigma =  30\n",
      "Train Accuracy:  98.3\n",
      "Test Accuracy:  98.88\n",
      "Train Error:  0.1970404766247653\n",
      "Test Error:  0.17459397047844433\n",
      "For Sigma =  35\n",
      "Train Accuracy:  98.3\n",
      "Test Accuracy:  98.88\n",
      "Train Error:  0.19710989254897207\n",
      "Test Error:  0.17467968598050013\n"
     ]
    }
   ],
   "source": [
    "sigmas = [0.01, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75, 1, 3, 5, 7, 10, 12, 15, 17, 20, 25, 30, 35]\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "train_error = []\n",
    "test_error = []\n",
    "for sigma in sigmas:\n",
    "  print(\"For Sigma = \", sigma)\n",
    "  y_pred, W = calcWeight(X_train, X_train, sigma)\n",
    "  y_pred_test = pred(X_test, X_train, sigma, W)\n",
    "  print(\"Train Accuracy: \", (acc(y_train, y_pred)))\n",
    "  print(\"Test Accuracy: \", acc(y_test, y_pred_test))\n",
    "  print(\"Train Error: \", mse(y_train, y_pred)[0])\n",
    "  print(\"Test Error: \", mse(y_test, y_pred_test)[0])\n",
    "  train_accuracy.append(acc(y_train, y_pred))\n",
    "  test_accuracy.append(acc(y_test, y_pred_test))\n",
    "  train_error.append(mse(y_train, y_pred)[0])\n",
    "  test_error.append(mse(y_test, y_pred_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "kXJ9NT27FbRP",
    "outputId": "6b7a447c-b7d2-4395-ce50-49f86bbfca61"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEWCAYAAABfdFHAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1fn48c9DQggQZF+CgKD4RVAgSNRWXKBIBTcEFFyqYhVEBUG/Vm21Lba1X/Wn1VpXrAqKC6LigkoVBKWisggq4IIiCgoY2beQkDy/P86ZMISZySSZO5OQ5/16zWtm7vrMnbn3mXPuveeIqmKMMcYEpVaqAzDGGHNgs0RjjDEmUJZojDHGBMoSjTHGmEBZojHGGBMoSzTGGGMCVS0TjYi8KSKXJHraVBKRVSJySqrjMPsTkWUi0jvG+DkicnkSQ0o4cZ4QkU0iMj/By/6DiPw7kctMJdtXyy9piUZEtoc9ikVkV9j7C8uzLFUdoKqTEj1tVeQTZWg7FYpIQdj7hyuwvPEiMjmIWA9Uqnqkqs6BxGw/ERkqIp+LyDYRWS4iZ5caf62IrBORrSLyuIjU8cPTReQ5EdksIjNE5KCwef4gItdVIqwTgH5AG1U9thLL2Y+q/l1V40rE9vvcS0QuEJGFfl9f648FJyRguUnfxklLNKqaFXoA3wNnhg17OjSdiKQnK6bqwCfK0HZ7GrgzbLuNSnV8ieb/WVfLknY8RORgYDJwHXAQ8DvgGRFp4cefCtwE9AUOAQ4FbvWzDwYUaAZsAUb6eToAZwH3VSK0Q4BVqrqjEsswCeL/NNwL/B1oCbQDHgQGJmHdid8HVTXpD2AVcIp/3RtYA9wIrAOeAhoD04E8YJN/3SZs/jnA5f71cOC/wF1+2m+BARWctgPwHrANmAk8AEyO8hniifGvwPt+eW8BzcLGXwR8B2wAbg7fJjG220Tgb2HvzwCWAJuBeUC3sHE3Aj/4dX+JO3D1BwqAQmA78EmU9dwEfOPnXQ4MKjV+BPB52Pij/fC2wEt+m2wA7vfDx4dvR6A97oCZHratbvPbahfQEbg0bB0rgStKxTDQf/atPtb+wLnAolLTXQe8EuEz9gE+C3v/NrAg7P1c4Ozw32u07VfWd11qvccBP5Ualgf80r9+Bvh72Li+wLqw7/QK/3oU8KB//RrQK479rjXwKrAR+BoY4YdfBuQDRf5z3Rph3uH+892PS3JfAH3LWnbp7z/su78E94fzZ+BmPy7a9h3ufwPbcPvshXHuH72BNbH2CT+8Fnt/8xuA54EmFdlXgdOBxbjf5WpgfNi4TNyfjA24fXYB0DLCMhr6z39ujO8yaswV3MZz2H8fPAK3X2z022to2PpPw+372/w2vT7mb6+sH2cQD/ZPNHuAO4A6QF2gKTAEqAc0AKYCL4fNP4d9k0ch7uCXBlwJ/AhIBab9AJeEMnBVCVuJnmjiifEb4H/8Z5oD3O7HdfFf8kn+M//Db4O4Ew3QA/gJd+BK8z+qVX55nXA/8tZhP7zDSu/0MdZzLu7AUQsYBuwAssPG/QAcA4j/QR7iY/gEuAeoj9upToi0TiInmu+BI4F0oDZuhz3Mr+NkYCd7E9qxuINdPx/jwbidog5up+gctq7FwJAIn7Eu7uDazK9vvf9cDfy4XUDTCL/X/bZfrO86wnrTgHdxJZA04GzcH636fvwnwLCw6Zv5bdXUb5Mp/nNOAa4GBgFPxLnfvYf7V5wJ5OAS3K/C9o3/xph3OO43eq3fXsP8d9AkjmWXbLOw7/5Rv626A7tD31mE30p93H7Yyb/PBo4sa/8IO7as8a9j7RNjgQ+BNn7bPgI8W5F91a+zK+532Q33uwr9YbkC96egnv/uewIHRVhGf7+O9BjfR6yYy7WNo+yDDf32utS/74FLWF389GuBE/3rxvh9M2q88fxAE/1g/0RTAGTGmD4H2FRqo4Qnj6/DxtXzG7lVeabFFU33APXCxk8u/YWUM8Zbwt5fBczwr/8EPFdqZyqI9uONtCMBDwF/LTX+S9xBuSMuCZ0C1C41zX4/sjg+2xJgoH/9H2BshGl+iTu47LdzlF4nkRPNX8qI4eXQenE71T1RpnsIuM2/PhJX2qwTZdq5uOqoX+BKIc/jdvI+wKdRfq/7bb9Y33WU9V6GO3jtwSXQ08PGfQP0D3tf22+r9rikezvwKTABl3yWAM1x/0ZDB/uMCOtsiyuxNAgb9n/AxLB9o6xEU/KnzA+bj/u3X9ayS7ZZ2HffptRyzovyW6mP+/c/BKgb7/7h3/dmb6KJtU98zr6ls2zcH9J0Krivhk1/L/63CvyWUjUPUea5EF+KjTFNrJjLtY0j7YO4PxJzS03zCPBn//p7XOLcL1FGelSVuvA8Vc0PvRGReiLyiIh8JyJbcTtQIxFJizL/utALVd3pX2aVc9rWwMawYeAyekRxxrgu7PXOsJhahy9bXb34hmjriuIQ4H/9ieHNIrIZt8O3VtWvgXG4H9RP/gRy63gXLCIXi8iSsOUehftnjV/HNxFmawt8p6p7yvk5QvbZ1iIyQEQ+FJGNPobT4ogBYBJwgYgI7iD4vKrujjLtu7iD0Un+9Rxcoj7Zvy+PaN/1PvzVSnf69Wb4df1bRHL8JNtx525CQq+3qXOTqnZT1ZG4qpOHcaXLXL+sDNwBrbTQ73tb2LDvcKXBeP2g/igTNn/rCi47ru3l941huKrCtSLyuogcUY6YQ8uJtU8cAkwL+71/jkucLSnnvioix4nIbBHJE5EtPu7Q7/Yp3B+150TkRxG5U0RqR1jMBqBZGeerY8UcEtc2DhO+Dx4CHFfq+HIh7k85uMR/GvCdiLwrIr+MteCqkmi01Pv/xRV1j1PVg3AHAnD/6IKyFmgiIvXChrWNMX1lYlwbvmy/zqblC5fVuH/ujcIe9VT1WQBVfUZVT8D9YBRXNQn7b+t9iMghuCL3aFzVUSNgadjnWo2r0ooUT7soO8cOXOkxpFWEaUri8ldZvYirxmzpY3gjjhhQ1Q9x/zhPBC7A7dzRlE4071J2oom5/eKQA7ynqgtVtVhVFwAf4f5pAyzDVXWEdAfWq+o+BzcR6QocjyvZdMWdm1JcvX+3COv9Eff7bhA2rB2uujBeB/sEHj7/jwladsh+21dV/6Oq/XD/2r/A/T4jifk7i7FPrMadqw3flzJV9QfKv68+gztX1VZVG+L+CIhff6Gq3qqqXXDf3RnAxRGW8QGuquvsCONCYsVclmi/4fDhq4F3Sy0/S1Wv9J9lgaoOBFrgahuej7XCqpJoSmuAqyPfLCJNgD8HvUJV/Q5YCIwXkQyfoc8MKMYXgDNE5AQRyQD+Qvm/i0eBUf4flIhIfRE5XUQaiEgnEfmVP2Dn+ziL/XzrgfYxriqpj/vB5QGIyKW4Ek3Iv4HrRaSnX29Hn5zm43bK230smSLSy8+zBDhJRNqJSEPg92V8tgxcvXMesEdEBgC/Dhv/GHCpiPQVkVoicnCpf7lP4k5aF6rqf2OsZx7uz8KxwHxVXYb/J4croUZS1vYrywLgxFAJRkR64JLip2GxXyYiXUSkEXALrkqohD/Y3w9co6rFuBPkod/SybgT5/tQ1dX+8/6f/2664arwynOZawvgGhGpLSLnAp2BNxK07JB9tq+ItBSRgSJSH3fw3c7e33JpS4DTRKSJiLTClWDwy4m1TzwM3OZ/x4hIcxEJXd1V3n21Aa50ly8ix+L+7IRi6CMiXX2tx1ZcVdd+n0VVt+Cq7B4QkbN97UltX8q/M46YyxLPb3g68D8icpFfd20ROUZEOvvj44Ui0lBVC/1nifadAFU30dyLO4n1M+6E14wkrfdC3LmGDcDfcCdco1W7VDhGf0C7GvfvZy3uPMKa8gSqqgtxFzXc7+f/GlePDu4gfbuPbR3uABE6uE/1zxtE5OMIy10O3I37V7Ue92/5/bDxU3HnA57BXXHyMu6EcBEuMXfE1d+uwVV5oKpv47blp8Ai3I841mfbBlyD+5e0Cbezvho2fj7uJOU9uBPS7+ISRMhTuOQY80Dnq0E+BpapaoEf/AGuCvCnKLPF3H5lUdV3cdU3L4jINlzJ7e+q+pYfPwNXtTYbtx2/Y/8/MZcCS1V1kX//Eq5UkYf7tz0hyurPx9Xf/whMw9W3zyxH+B8Bh+N+V7cB54SVtCq77JDS27cW7srBH3EXepyMu4gnkqdwF1Oswp1zmxI2LtY+8U/c7+st/518iPuzUZF99SrgL345f2Lff/qtcIlrK66q612ilLhV9W7/uW/Bfa+rcbUML5cVcxzK/A37ffDXwHm4bb+OvRdsgauWXiXutMEo3LEzqtDVViYCEZkCfKGqgZeoTOKISF3cid+jVXVFquM5EIjIcNxFNZW+YdDUPFW1RJMSvmh4mK+O6Y+7V+PlsuYzVc6VuHtiLMkYUwXYXfj7aoWrhmiKKx5fqaqLUxuSKQ8RWYU7+RrrRKoxJoms6swYY0ygrOrMGGNMoKp11VmzZs20ffv2qQ7DGGOqlUWLFv2sqs2Ttb5qnWjat2/PwoULUx2GMcZUKyLyXTLXZ1VnxhhjAmWJxhhjTKAs0RhjjAmUJRpjjDGBskRjjDEmUIElGhF5XER+EpGlYcOaiMjbIrLCPzf2w0VE7hORr0XkUxE5Oqi4jDHGJFeQJZqJuN4Kw90EzFLVw4FZ/j3AAFyrsIcDI3G9JBpjjDkABHYfjaq+JyLtSw0eiOtoClxPiHOAG/3wJ33HTR+KSCMRyVbVtUHE9t/v/8tb37wVcVztWrW57OjLaN0g7g4pjTHGxJDsGzZbhiWPdeztdvRg9u1GdI0ftl+iEZGRuFIP7dq1q1AQH6z+gL+997eI4xRlxjczmHvpXGpVuG8rY4wxISk7kvrSS7lb9FTVCaqaq6q5zZtXrAWF3/X6HcV/Lo74mHT2JOatnseERdH6jjJBW7x2MWc8cwb/+5//5cM1H2INvxpTvSW7RLM+VCUmItm4zqnA9S3eNmy6NlSsv/FKu6jbRUz6ZBI3zbyJUw87leb1K9ccUJ20OtROq52g6A58T33yFCOnj6Re7Xq89c1b/OPDf9D2oLYM6TyEc488l1+0+YWVNI2pZpKdaF4FLsF1qXoJ8ErY8NEi8hyuO9ItQZ2fKYuI8PDpD9P1oa4cet+hlV5eo8xGPDHwCc4+wrpHiaWwqJDr37qe++bfx8mHnMzz5z5PRloGr335Gi98/gIPLnyQez+6l4MbHMyQzkM4p8s59GrXy5KOMdVAYP3RiMizuBP/zXB9z/8Z11vl80A7XF/oQ1V1o4gIcD/uKrWdwKWqWmZrmbm5uRpUo5ofrP6A91e/X+nlPL/seRb8uICbT7yZW3vfSlqttAREd2BZv309Q18Yynvfvce448ZxZ7879ysFbt29lelfTWfq8qm8ueJNdhftJjsrm8GdB3Nul3M5od0Jtm2NiZOILFLV3KStrzrXfweZaBIlf08+o98YzWOLH6N/x/48PfhpmtRtkuqwqoz5P8xn8JTBbNy1kUfPfJQLu11Y5jzbdm/j9RWvM3X5VN5Y8Qb5e/JpWb8lgzsP5pwu53DSISeRXqtaN0xuTKAs0ZRDdUg0IRMWTWD0G6Np27AtLw19ie6tuqc6pJR7fPHjXPn6lWRnZTNt2DR6ZPco9zK2F2znjRVv8MLyF3h9xevsLNxJ83rNGXTEIM498lx6t++9X9JRheXLYdYsmDsXduxI1CcyJnlGj4bTTqvYvJZoyqE6JRqAD9d8yJDnh7Bp1yb+fda/uaDrBakOKSUKigoYN2McDy18iFMOPYVnhzxLs3rNKr3cnYU7eXPFm0xdPpXpX01nR+EOmtZtyqAjBnFy44vI/+p45sxOZ9YsWLfOzdO+PVTw4kVjUurGG2HIkIrNa4mmHKpbogFYt30dQ6cOZe73c6OejziQrd22lnOmnsO81fO44fgbuK3vbYFUc61Zt4t/PvcpL7+5jW8WtUc3dAQgs+EWjjtxB+ef1YJT+6VT0ztoVVUKigrYWbiz4o89kYfvKtxFRloG9WrXS/gjMz3TLgSphGQnGqvITrJWWa2YdfEsrn/reu796F4Wr1vM8+c+T4v6LVIdWuDmrZ7HOc+fw5bdW5hyzhSGHjk0YcvesQP++19XHTZrFixeXBfV48jKgv4nFdG6+1LWtXia93Y9yLsFW/lkYyM+WDKQIbuH0OagNgmLI2h7ivdUOgGUfhRrcbnjyEzPjJoEmtVrVpIMCosK91nXuu3rIsag5b+ljrrpdROavDLSMhCk3HGkStuGbRNSE5AMVqJJocmfTmbkayNpWq8pLw59kWMPPjbVIQVCVXlk0SNc8+Y1tGvYjmnDptG1ZddKLbOwEBYs2JtY5s1zw2rXhl/+Ek45Bfr2hWOOccNCdu/Zzdsr3+aF5S/w8hcvs2X3lkp+uqolTdKon1G/7ANreuVKE4m8wk9V2V20u3Klqjgeu4t2JyzmquCh0x9iVO6oCs1rVWflUN0TDcCSdUsYNGUQP277kQdOe4DLj7481SElVP6efK5+/WoeX/I4AzoO4OnBT9O4buNyL0cVli7dm1jefRe2bQMRyMnZm1hOOAHq149vmQVFBbz//fts3b213PGkSlqtNOrXjp5IalI1bHkVFRexa8+u6IloT/VKRN1adqND4w4VmtcSTTkcCIkGYMPODVzw0gW89c1bjDx6JPcNuI866XVSHValrd6ymiHPD2HBjwu45cRbGN97fLn+Ca9atTexzJoFP/l2JDp2dEnllFOgTx9o2jSY+I05UFmiKYeqmmhUXbXOv//t/nkXx1UFrmzYtYFNuzZRJz2T7KxWpNeqvv9Od+3Zybpt6yhGaVW/JfUzsso3/y74wTdC1LLl3sTSty9UsC1VY4xnFwNUYxs3wuTJLsF89hnUqwe//rV7LpsAzVi9ZScfrJnH2lrpnNjuxGp4kYDy5c9f8s3aj8lq1oCT2p1Ew8zyJRmAtDTo2dMlly5dXBWZMaZ6skRTScXFMGeOSy4vvQS7d7sT0A8/DOedBw0blneJ7fg8bweDpgxizqZvuPvXdzPm2DFIjCPtjoIdrN2+lrXb1u77XGrYtoJtlfmocVFVCosLGdhpIE8OepKD6hwU+DqNMVWbJZoK+vFHmDgRHnsMVq6ERo1g5Ei47DLoXsmb/js378z8EfO5eNrFjJ0xlvk/zKd/x/7lSiC1a9WmVVYrshtkc1jjwzih7Qk0zGyYlMs3OzbpyKU9LrX7HIwxgJ2jKZc9e+CNN1zp5Y03oKgIeveGyy+HwYOhbt3Erq9Yi/n73L/zp9l/KrnPoF7temRnZZPdINs9h78Oe25St4kd6I0xEdnFAOWQrETzzTfw+OPwxBOwdi20agXDh8NvfwuHHx746vl207cUFBWQ3SCbBhkNYlajGWNMWexigCTYvRvy8yEry510jiQ/H6ZNc6WXd96BWrVcA3YjRsCAAfveBBi0il4rb4wxVUGNrFu57z53TuXMM6NPM2AAXHABfPst/O1v8P338NprcNZZyU0yxhhT3dXIEk2fPu556dLo06xc6VpGff55V5oxxhhTMTXyEJqbC2PHwpYYzVzt3OnOxViSMcaYyqmxh9HGjWHrVnflWCQ7dsR7o6UxxphYamyiadTIPUcq1RQXuyZQLNEYY0zl1fhEs2nT/uPy892zJRpjjKm8GptoGvuW6jdv3n/czp3u2RKNMcZUXkoSjYiMFZGlIrJMRMb5YeNF5AcRWeIfpwUZQ6gNskhVZ6FEE2+/JsYYY6JL+uXNInIUMAI4FigAZojIdD/6HlW9Kxlx1PHdvRQU7D9uxw73bCUaY4ypvFTcR9MZ+EhVdwKIyLvA4GQHEbrpMlKisaozY4xJnFRUnS0FThSRpiJSDzgNaOvHjRaRT0XkcREpf3+/5RBKNIWF+4+zRGOMMYmT9ESjqp8DdwBvATOAJUAR8BBwGJADrAXujjS/iIwUkYUisjAvL6/CcWRkuGcr0RhjTLBScjGAqj6mqj1V9SRgE/CVqq5X1SJVLQYexZ3DiTTvBFXNVdXc5s2bVzgGK9EYY0xypOqqsxb+uR3u/MwzIpIdNskgXBVbYGKVaEIXA9hVZ8YYU3mpalTzRRFpChQCV6vqZhH5l4jkAAqsAq4IMgAr0RhjTHKkJNGo6okRhl2UzBgs0RhjTHLU2JYB7GIAY4xJjhqbaGKVaHbscD1vWgdnxhhTeTU+0UQr0dSvDyLJjckYYw5ENTbRpKW5Ts2inaOxajNjjEmMGptowJVqLNEYY0ywanSiyciIXnVmicYYYxKjRieaaCUa68bZGGMSp0YnmlglGmsVwBhjEqNGJxo7R2OMMcGr0YkmI8MSjTHGBK1GJ5rate1iAGOMCZolmiitN1uiMcaYxKjRiaZ+/b3tmoWziwGMMSZxanSiadwYNm3ad5iqVZ0ZY0wi1ehE06gRbN6877D8fPdsicYYYxKjRieaxo33TzTWRYAxxiRWjU40jRq5qjPVvcNC3ThbojHGmMSo0YmmcWMoKtqbXGBvicYuBjDGmMSo0YmmUSP3HH5BgFWdGWNMYtXoRJOZ6Z7D76WxRGOMMYlVoxNNerp73rNn7zA7R2OMMYlliYZ9E42VaIwxJrFSkmhEZKyILBWRZSIyzg9rIiJvi8gK/9w46DhiJRq7GMAYYxIj6YlGRI4CRgDHAt2BM0SkI3ATMEtVDwdm+feBshKNMcYELxUlms7AR6q6U1X3AO8Cg4GBwCQ/zSTg7KADsURjjDHBS0WiWQqcKCJNRaQecBrQFmipqmv9NOuAlpFmFpGRIrJQRBbm5eVVKpC0NPdsFwMYY0xwkp5oVPVz4A7gLWAGsAQoKjWNArr/3KCqE1Q1V1VzmzdvXqlYopVoatVynaIZY4ypvJRcDKCqj6lqT1U9CdgEfAWsF5FsAP/8U9BxREs09euDSNBrN8aYmiFVV5218M/tcOdnngFeBS7xk1wCvBJ0HKFEUxRWnrIuAowxJrHSU7TeF0WkKVAIXK2qm0XkduB5EbkM+A4YGnQQ0Uo0lmiMMSZxUpJoVPXECMM2AH2TGUe0lgEs0RhjTOJYywBYicYYY4IUV4nG36XfGtgFrFLV4kCjSpJYFwMYY4xJjKiJRkQaAlcD5wMZQB6QCbQUkQ+BB1V1dlKiDEik+2h27oQWLVITjzHGHIhilWheAJ4ETlTVfTo8FpGewEUicqiqPhZkgEGyqjNjjAle1ESjqv1ijFsELAokoiSyiwGMMSZ4cV91JiLNgbFAXeBhVV0RWFRJYiUaY4wJXnmuOrsb+A8wDXeDZbVnicYYY4IXNdGIyH9E5KSwQRnAKv+oE2xYyVG6ZQBVu+rMGGMSLVaJZihwpog8KyKHAX8E/g/4J3BVMoILWukSTUGBSzaZmamLyRhjDjSxLgbYAvxORA4FbgN+BEaXvgKtOiudaAoL3XPt2qmJxxhjDkSx7qM5DLgSKAD+FzgMmCIirwMPqGpRtHmri9KJJvScnqoW4Iwx5gAUq+rsWeAlYDbwlKrOVdVTgc24vmSqvdI3bFqJxhhjEi/Wf/c6wLdAFlByHZaqPikiU4MOLBlq+TRrJRpjjAlOrEPqVcD9uKqzUeEjVHVXkEEli4hLKlaiMcaY4MS6GOB94P0kxpIS4Ykm9GyJxhhjEifWfTSvicgZIrLfYVdEDhWRv4jIb4MNL3iRSjRWdWaMMYkT65A6ArgO+KeIbGRv683tgW+A+1U18O6Wg5aevveGTSvRGGNM4sWqOlsH3ADcICLtgWxcfzRfqerOpESXBFaiMcaYYMV1SFXVVbimZw44do7GGGOCVaO7cgYr0RhjTNBqfKJJS7PLm40xJkhlJhoROVNEEpqQRORaEVkmIkt9o52ZIjJRRL4VkSX+kZPIdUYTqerMSjTGGJM48SSQYcAKEblTRI6o7ApF5GDgGiBXVY8C0oDz/OjfqWqOfyyp7LriYTdsGmNMsMpMNKr6G6AH7pLmiSLygYiMFJEGlVhvOlBXRNJxzdv8WIllVYqVaIwxJlhxVYmp6lbgBeA53GXOg4CPRWRMeVeoqj8AdwHfA2uBLaoaaqTzNhH5VETuEZGInav5JLdQRBbm5eWVd/X7sRKNMcYEK55zNGeJyDRgDlAbOFZVBwDdcd0HlIuINAYGAh2A1kB9EfkN8HvgCOAYoAlwY6T5VXWCquaqam7z5s3Lu/r92OXNxhgTrHgqiYYA96jqe+EDVXWniFxWgXWeAnyrqnkAIvIScLyqTvbjd4vIE8D1FVh2uYW3DGCXNxtjTOLFU3U2HpgfeiMidX1LAajqrAqs83vgFyJST0QE6At8LiLZfvkCnA0srcCyy81KNMYYE6x4Es1UoDjsfZEfViGq+hHufM/HwGc+hgnA0yLymR/WDPhbRddRHpHuo7ESjTHGJE48h9R0VS0IvVHVAhHJqMxKVfXPwJ9LDf5VZZZZUenpUOA/nZVojDEm8eIp0eSJyFmhNyIyEPg5uJCSy5qgMcaYYMVzSB2Fq9a6HxBgNXBxoFElkZ2jMcaYYJWZaFT1G9zJ+yz/fnvgUSWRlWiMMSZYcR1SReR04Egg010UBqr6lwDjShq7YdMYY4IVzw2bD+PaOxuDqzo7Fzgk4LiSxpqgMcaYYMVzMcDxqnoxsElVbwV+CfxPsGElT6QbNtPSUhePMcYcaOJJNPn+eaeItAYKce2dHRBKl2jS08HXDhpjjEmAeCqJXhORRsD/w91kqcCjgUaVRKVv2LTzM8YYk1gxE43v8GyWqm4GXhSR6UCmqm5JSnRJULpEY4nGGGMSK2bVmaoWAw+Evd99ICUZ2P+qM7sQwBhjEiueczSzRGSIyIF55sJKNMYYE6x4Es0VuEY0d4vIVhHZJiJbA44raaxEY4wxwYqnZYDKdNlc5VmJxhhjglVmohGRkyINL90RWnVlJRpjjAlWPIfV34W9zgSOBRaRomb9E81KNMYYE6x4qs7ODH8vIm2BewOLKMnS00EVioutRGOMMUGI52KA0tYAnRMdSKqEmpspKrIbNo0xJgjxnKP5F641AHCJKQfXQsABIVSC2bNnbxM0xhhjEieew+rCsNd7gGdV9f2A4km68ERjJRpjjJMo5gIAABq5SURBVEm8eBLNC0C+qhYBiEiaiNRT1Z3BhpYcVqIxxphgxdUyAFA37H1dYGYw4SSflWiMMSZY8SSazPDum/3repVZqYhcKyLLRGSpiDwrIpki0kFEPhKRr0VkiohkVGYd8SpdorFEY4wxiRVPotkhIkeH3ohIT2BXRVcoIgcD1wC5qnoUkAacB9wB3KOqHYFNwGUVXUd5lC7RWNWZMcYkVjyH1XHAVBH5EdeVcytc186VXW9dESnElY7W4m4AvcCPnwSMBx6q5HrKDsRKNMYYE6h4bthcICJHAJ38oC9VtbCiK1TVH0TkLuB7XMnoLVxLA5tV1d+jzxrg4IquozxCiSZ0H42VaIwxJrHKrDoTkauB+qq6VFWXAlkiclVFVygijYGBQAegNVAf6F+O+UeKyEIRWZiXl1fRMEqEbti0Eo0xxgQjnnM0I3wPmwCo6iZgRCXWeQrwrarm+ZLRS0AvoJGIhMoTbYAfIs2sqhNUNVdVc5s3b16JMBw7R2OMMcGKJ9GkhXd6JiJpQGWuCPse+IWI1PPL7QssB2YD5/hpLgFeqcQ64mbnaIwxJljxJJoZwBQR6SsifYFn/bAKUdWPcDeBfgx85mOYANwIXCciXwNNgccquo7ysBKNMcYEK57D6o3ASOBK//5t4NHKrFRV/wz8udTglbguCJLKSjTGGBOsMks0qlqsqg+r6jmqeg6umutfwYeWHFaiMcaYYMV1WBWRHsD5wFDgW9wJ/AOCNUFjjDHBippoROR/cMnlfOBnYAogqtonSbElhVWdGWNMsGKVaL4A5gJnqOrX4NooS0pUSRR+H01RkVWdGWNMosU6RzMY1zTMbBF51F9xJjGmr5ZCiSU/3z1bicYYYxIraqJR1ZdV9TzgCNw9LuOAFiLykIj8OlkBBi2UaHbt2ve9McaYxIjnqrMdqvqMqp6Ju2N/Me6S5wOClWiMMSZY8dywWUJVN/kmYPoGFVCyWYnGGGOCVa5EcyCyEo0xxgTLEo2VaIwxJlCWaKxEY4wxgbJEYyUaY4wJVI1PNKEbNq1EY4wxwajxiaZ01ZmVaIwxJrEs0ZSqOrMSjTHGJJYlGrsYwBhjAmWJxi4GMMaYQFmisRKNMcYEqsYnmlq1QMRKNMYYE5Qan2jAJRcr0RhjTDAs0eASjZVojDEmGJZocDdtWonGGGOCkfT/7yLSCZgSNuhQ4E9AI2AEkOeH/0FV30hGTOFVZ1aiMcaYxEr6YVVVvwRyAEQkDfgBmAZcCtyjqnclOyY7R2OMMcFJddVZX+AbVf0ulUHYORpjjAlOqhPNecCzYe9Hi8inIvK4iDSONIOIjBSRhSKyMC8vL9Ik5ZaeDgUF7rWVaIwxJrFSlmhEJAM4C5jqBz0EHIarVlsL3B1pPt+VdK6q5jZv3jwhsYSXYqxEY4wxiZXKEs0A4GNVXQ+gqutVtUhVi4FHgWOTFUh4crESjTHGJFYqE835hFWbiUh22LhBwNJkBWKJxhhjgpOSiiIRqQ/0A64IG3yniOQACqwqNS5Qoc7PwKrOjDEm0VJyWFXVHUDTUsMuSkUsYCUaY4wJUqqvOqsS7GIAY4wJjiUa9iaXtDTXkrMxxpjEsUTD3kRjpRljjEk8SzTsTTB2fsYYYxLPEg1WojHGmCBZosFKNMYYEyRLNFiJxhhjgmSJhr03bFqJxhhjEs8SDVZ1ZowxQbJEg1WdGWNMkCzRYCUaY4wJkiUarERjjDFBskMrVqIxNUthYSFr1qwhPz8/1aGYgGVmZtKmTRtqp/jgZokGK9GYmmXNmjU0aNCA9u3bI9a43wFLVdmwYQNr1qyhQ4cOKY3Fqs6wEo2pWfLz82natKklmQOciNC0adMqUXK1RIOVaEzNY0mmZqgq37MlGuyGTWOMCZIlGqxEY0wybdiwgZycHHJycmjVqhUHH3xwyfuCgoKY8y5cuJBrrrmmzHUcf/zxiQrXJIAdWrFzNMYkU9OmTVmyZAkA48ePJysri+uvv75k/J49e0iP8q8vNzeX3NzcMtcxb968xASbREVFRaSFqlcOMJZosBKNqbnGzRjHknVLErrMnFY53Nv/3nLNM3z4cDIzM1m8eDG9evXivPPOY+zYseTn51O3bl2eeOIJOnXqxJw5c7jrrruYPn0648eP5/vvv2flypV8//33jBs3rqS0k5WVxfbt25kzZw7jx4+nWbNmLF26lJ49ezJ58mREhDfeeIPrrruO+vXr06tXL1auXMn06dP3iWvVqlVcdNFF7NixA4D777+/pLR0xx13MHnyZGrVqsWAAQO4/fbb+frrrxk1ahR5eXmkpaUxdepUVq9eXRIzwOjRo8nNzWX48OG0b9+eYcOG8fbbb3PDDTewbds2JkyYQEFBAR07duSpp56iXr16rF+/nlGjRrFy5UoAHnroIWbMmEGTJk0YN24cADfffDMtWrRg7NixFf/yAmKHVqxEY0xVsGbNGubNm0daWhpbt25l7ty5pKenM3PmTP7whz/w4osv7jfPF198wezZs9m2bRudOnXiyiuv3O+ekcWLF7Ns2TJat25Nr169eP/998nNzeWKK67gvffeo0OHDpx//vkRY2rRogVvv/02mZmZrFixgvPPP5+FCxfy5ptv8sorr/DRRx9Rr149Nm7cCMCFF17ITTfdxKBBg8jPz6e4uJjVq1fH/NxNmzbl448/Bly14ogRIwC45ZZbeOyxxxgzZgzXXHMNJ598MtOmTaOoqIjt27fTunVrBg8ezLhx4yguLua5555j/vz55d7uyZD0RCMinYApYYMOBf4EPOmHtwdWAUNVdVMyYrJEY2qq8pY8gnTuueeWVB1t2bKFSy65hBUrViAiFBYWRpzn9NNPp06dOtSpU4cWLVqwfv162rRps880xx57bMmwnJwcVq1aRVZWFoceemjJ/SXnn38+EyZM2G/5hYWFjB49miVLlpCWlsZXX30FwMyZM7n00kupV68eAE2aNGHbtm388MMPDBo0CHA3S8Zj2LBhJa+XLl3KLbfcwubNm9m+fTunnnoqAO+88w5PPvkkAGlpaTRs2JCGDRvStGlTFi9ezPr16+nRowdNmzaNa53JlvREo6pfAjkAIpIG/ABMA24CZqnq7SJyk39/YzJisqozY1Kvfv36Ja//+Mc/0qdPH6ZNm8aqVavo3bt3xHnq1KlT8jotLY09e/ZUaJpo7rnnHlq2bMknn3xCcXFx3MkjXHp6OsXFxSXvS9/XEv65hw8fzssvv0z37t2ZOHEic+bMibnsyy+/nIkTJ7Ju3Tp++9vflju2ZEn1VWd9gW9U9TtgIDDJD58EnJ2sIKxEY0zVsmXLFg4++GAAJk6cmPDld+rUiZUrV7Jq1SoApkyZEnG6LVu2kJ2dTa1atXjqqacoKioCoF+/fjzxxBPs3LkTgI0bN9KgQQPatGnDyy+/DMDu3bvZuXMnhxxyCMuXL2f37t1s3ryZWbNmRY1r27ZtZGdnU1hYyNNPP10yvG/fvjz00EOAu2hgy5YtAAwaNIgZM2awYMGCktJPVZTqRHMe8Kx/3VJV1/rX64CWkWYQkZEislBEFubl5SUkiNCFHlaiMaZquOGGG/j9739Pjx49ylUCiVfdunV58MEH6d+/Pz179qRBgwY0bNhwv+muuuoqJk2aRPfu3fniiy9KSh/9+/fnrLPOIjc3l5ycHO666y4AnnrqKe677z66devG8ccfz7p162jbti1Dhw7lqKOOYujQofTo0SNqXH/961857rjj6NWrF0cccUTJ8H/+85/Mnj2brl270rNnT5YvXw5ARkYGffr0YejQoVX6ijVR1dSsWCQD+BE4UlXXi8hmVW0UNn6TqjaOtYzc3FxduHBhpWN54AEYPRrGjYN77qn04oyp0j7//HM6d+6c6jBSbvv27WRlZaGqXH311Rx++OFce+21qQ6rXIqLizn66KOZOnUqhx9+eMRpIn3fIrJIVcu+TjxBUlmiGQB8rKrr/fv1IpIN4J9/SlYgdo7GmJrn0UcfJScnhyOPPJItW7ZwxRVXpDqkclm+fDkdO3akb9++UZNMVZHKQ+v57K02A3gVuAS43T+/kqxA7ByNMTXPtddeW+1KMOG6dOlScl9NVZeSEo2I1Af6AS+FDb4d6CciK4BT/PuksBKNMcYEJyWHVlXdATQtNWwD7iq0pLMSjTHGBCfVV51VCVaiMcaY4FiiwUo0xhgTJPsPj5VojEmmDRs20LevqyVft24daWlpNG/eHID58+eTkZERc/45c+aQkZFhXQFUI3ZoxTo+MyaZyuomoCxz5swhKysr5YnmQG7WP9Es0WBVZ6bmGjcOliS2lwBycuDecrbVuWjRIq677jq2b99Os2bNmDhxItnZ2dx33308/PDDpKen06VLF26//XYefvhh0tLSmDx5Mv/617848cQTS5Yzf/78iN0LFBUVceONNzJjxgxq1arFiBEjGDNmDAsWLGDs2LHs2LGDOnXqMGvWLF588UUWLlzI/fffD8AZZ5zB9ddfT+/evcnKyuKKK65g5syZPPDAA7zzzju89tpr7Nq1i+OPP55HHnkEEYnYXcCtt97K4MGDOfts17rWhRdeyNChQxk4cGDCtn1VZYkGqzozJpVUlTFjxvDKK6/QvHlzpkyZws0338zjjz/O7bffzrfffkudOnXYvHkzjRo1YtSoUVFLQUcccUTE7gUmTJjAqlWrWLJkCenp6WzcuJGCggKGDRvGlClTOOaYY9i6dSt169aNGeuOHTs47rjjuPvuuwF3L8uf/vQnAC666CKmT5/OmWeeGbG7gMsuu4x77rmHs88+my1btjBv3jwmTZoUa3UHDDu0YiUaU3OVt+QRhN27d7N06VL69esHuCqp7OxsALp168aFF17I2WefXVISiCVa9wIzZ85k1KhRJT13NmnShM8++4zs7GyOOeYYAA466KAyl5+WlsaQIUNK3s+ePZs777yTnTt3snHjRo488kh69+4dsbuAk08+mauuuoq8vDxefPFFhgwZErUn0QNNzfiUZbASjTGpo6oceeSRfPDBB/uNe/3113nvvfd47bXXuO222/jss89iLive7gViidWsf2ZmZsl5mfz8fK666ioWLlxI27ZtGT9+/H5dAJR28cUXM3nyZJ577jmeeOKJcsdWXdnlzViJxphUqlOnDnl5eSWJprCwkGXLlpX0TtmnTx/uuOMOtmzZwvbt22nQoAHbtm2LuKxo3Qv069ePRx55pKQl6I0bN9KpUyfWrl3LggULANdE/549e2jfvj1LliwpWX+0XitDSaVZs2Zs376dF154ASBqdwHg+pu51xcju3TpUuFtVt1YosFKNMakUq1atXjhhRe48cYb6d69Ozk5OcybN4+ioiJ+85vf0LVrV3r06ME111xDo0aNOPPMM5k2bRo5OTnMnTt3n2VF617g8ssvp127dnTr1o3u3bvzzDPPkJGRwZQpUxgzZgzdu3enX79+5Ofn06tXLzp06ECXLl245pprOProoyPG3ahRI0aMGMFRRx3FqaeeWlIFB5G7CwBo2bIlnTt35tJLLw1gS1ZdKesmIBES1U1AQQH88Y/whz9AhC4pjDmgWDcBqbNz5066du3Kxx9/HLH/myDU9G4CqoyMDLjjDksyxpjgzJw5k86dOzNmzJikJZmqwiqLjDEmCU455RS+++67VIeRElaiMaYGqs5V5iZ+VeV7tkRjTA2TmZnJhg0bqsxByARDVdmwYUPJfTypZFVnxtQwbdq0Yc2aNeTl5aU6FBOwzMxM2rRpk+owLNEYU9PUrl2bDh06pDoMU4NY1ZkxxphAWaIxxhgTKEs0xhhjAlWtWwYQkTygohemNwN+TmA4QatO8VanWKF6xVudYoXqFW91ihUqF+8hqto8kcHEUq0TTWWIyMJkNsFQWdUp3uoUK1SveKtTrFC94q1OsUL1iteqzowxxgTKEo0xxphA1eREMyHVAZRTdYq3OsUK1Sve6hQrVK94q1OsUI3irbHnaIwxxiRHTS7RGGOMSQJLNMYYYwJVIxONiPQXkS9F5GsRuSnV8cQiIqtE5DMRWSIile9ONMFE5HER+UlEloYNayIib4vICv/cOJUxhkSJdbyI/OC37xIROS2VMYYTkbYiMltElovIMhEZ64dXue0bI9YquX1FJFNE5ovIJz7eW/3wDiLykT82TBGRjCoc60QR+TZs2+akOtZoatw5GhFJA74C+gFrgAXA+aq6PKWBRSEiq4BcVa2SN5KJyEnAduBJVT3KD7sT2Kiqt/tE3lhVb0xlnD6uSLGOB7ar6l2pjC0SEckGslX1YxFpACwCzgaGU8W2b4xYh1IFt6+ICFBfVbeLSG3gv8BY4DrgJVV9TkQeBj5R1YeqaKyjgOmq+kIq44tHTSzRHAt8raorVbUAeA4YmOKYqi1VfQ/YWGrwQGCSfz0Jd8BJuSixVlmqulZVP/avtwGfAwdTBbdvjFirJHW2+7e1/UOBXwGhA3dV2bbRYq02amKiORhYHfZ+DVV4h8D9oN4SkUUiMjLVwcSppaqu9a/XAS1TGUwcRovIp75qLeXVUJGISHugB/ARVXz7looVquj2FZE0EVkC/AS8DXwDbFbVPX6SKnNsKB2rqoa27W1+294jInVSGGJMNTHRVDcnqOrRwADgal/9U22oq5utyv++HgIOA3KAtcDdqQ1nfyKSBbwIjFPVreHjqtr2jRBrld2+qlqkqjlAG1xNxxEpDimq0rGKyFHA73ExHwM0AVJePR1NTUw0PwBtw9638cOqJFX9wT//BEzD7RBV3XpfZx+qu/8pxfFEparr/U5cDDxKFdu+vk7+ReBpVX3JD66S2zdSrFV9+wKo6mZgNvBLoJGIhDqErHLHhrBY+/vqSlXV3cATVMFtG1ITE80C4HB/dUkGcB7waopjikhE6vsTq4hIfeDXwNLYc1UJrwKX+NeXAK+kMJaYQgdsbxBVaPv6k8CPAZ+r6j/CRlW57Rst1qq6fUWkuYg08q/r4i4O+hx3ED/HT1ZVtm2kWL8I+7MhuHNJVWLbRlLjrjoD8JdY3gukAY+r6m0pDikiETkUV4oB1+32M1UtVhF5FuiNa7J8PfBn4GXgeaAdrhuHoaqa8pPwUWLtjavWUWAVcEXY+Y+UEpETgLnAZ0CxH/wH3LmPKrV9Y8R6PlVw+4pIN9zJ/jTcH+7nVfUvfp97DlcVtRj4jS8xpEyMWN8BmgMCLAFGhV00UKXUyERjjDEmeWpi1ZkxxpgkskRjjDEmUJZojDHGBMoSjTHGmEBZojHGGBMoSzQm4UTkZt/K7Ke+Vdnjkrz+VSLSLMrwz3xcb4lIq2TGFYmI5CSiRWMRqSsi7/qmSmqJyH0istR/3gUi0sFP90bonoygiMjMqtTUjEk9SzQmoUTkl8AZwNGq2g04hX3blitr/vSyp6qUPj6uhbj7PMoUcEw5QLkSTZR4fotrdbgIGAa0BrqpalfcjZKbAVT1NH93eZCeAq4KeB2mGrFEYxItG/g5dJObqv6sqj9CSYniTv8ve76IdPTDJ4rIwyLyEXCniBwmIjN8Q6JzReQIP92Z4voKWez/Nbf0w5v6EsoyEfk37ga2srwHdBSRY0XkA7/MeSLSyS9zuIi86m+KmyUiWSIyS0Q+9vEP9NO1F5Ev/Gf4SkSeFpFTROR9cf3FHOunq+8blZzv1zXQt0zxF2CYL/kNizRdpHgifJ4L2XsXezaw1jf7gqquUdVNYd9BM//6j+L6ZfqviDwrItf74XPENdK4UEQ+F5FjROQl/3n+FlqhiLzsv6Nlsm+Dr6/ibtQ0xlFVe9gjYQ8gC3eX8lfAg8DJYeNWATf71xfj+tIAmAhMB9L8+1nA4f71ccA7/nVj9t5kfDlwt399H/An//p03F3ozSLEtio0HLgfuAM4CEj3w04BXvSvh+Na723i36cDB/nXzYCvcQmtPbAH6Ir747YIeNyPGwi87Of5O+4uc4BGfvvU9+u5PyzGWNOVxFPqc2UA68Let/GfdQmuEcsepbcBriHGJUAm0ABYAVzvp5kD3OFfjwV+xCWvOj6Gpn5caNvUxTV/0jRsPSvC39ujZj+CrqYwNYy6zpl6AicCfYApInKTqk70kzwb9nxP2KxTVbVIXOu/xwNTXRNOgDvAgTuATvFtPGUA3/rhJwGD/fpfF5FNMUKcLSJFwKfALUBDYJKIHI5LULXDpn1b9zbtIsDfxbWeXYxrPj7UPP+3qvoZgIgsA2apqorIZ7hEBK6durNCpQbcAb5dhPhiTRceT7hm+Koxvw3W+JLZr/xjloicq6rhJaFewCuqmg/ki8hrpZYZav/vM2CZ+mZjRGQlrlHaDcA1IjLIT9cWONwPB9fQZ+uw96YGs0RjEk7deYI5wBx/sL0EV2qBfZu0D3+9wz/XwvUJEqlb2n8B/1DVV0WkNzC+AuH10bDeSkXkXmC2qg4S14/KnAgxgauaag70VNVCcT2fZvpx4W1hFYe9L2bvPibAEFX9MjwY2f9CiVjT7SCyXWGxAKCu6vJN4E0RWY9rdDFSlVs04Z+h9OdL99v/FOCXqrpTROaUiiHTx2WMnaMxiSUinXzpICQH1/BjyLCw5w9Kz6+uD5NvReRcvzwRke5+dEP2Ntt+Sdhs7wEX+OkH4KrY4hW+zOFlTPeTTzJ9gEPKsQ6A/wBjxBfTRKSHH74NV3VV1nRRqTv/kiYimX6eo0WktX9dC+jGvt8BwPvAmeL6o8/CXcBRHg2BTT7JHAH8IjTCx94KV01njCUak3BZuKqo5SLyKdCFfUsejf3wscC1UZZxIXCZiHwCLGNvV9vjcVVqi4Cfw6a/FTjJV1sNBr4vR7x3Av8nIouJXcJ/Gsj1JbSLgS/KsQ6Av+Kq5T71cf7VD58NdAldDBBjurK8BZzgX7cAXhORpbgqwj24c1IlVHUBrnrsU1zJ5zNgSzk+zwxcyeZz4Hbgw7BxPYEPdW9PlaaGs9abTdL46qbc8KorkxgicjRwrapeVI55svw5tXq4UuFIVf04AbH8E3i11DkhU4PZORpjDgCq+rGIzBaRNH+OLB4TRKQL7nzKpEQkGW+pJRkTzko0xhhjAmXnaIwxxgTKEo0xxphAWaIxxhgTKEs0xhhjAmWJxhhjTKD+P5h3HSv2tuORAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sigmas, train_accuracy, 'g', label='Training accuracy')\n",
    "plt.plot(sigmas, test_accuracy, 'b', label='Test accuracy')\n",
    "plt.title('Training and Test accuracy with 80% of points used as Centres')\n",
    "plt.xlabel('Spread Parameter (Sigma)')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bN_fr8K2bhNP"
   },
   "source": [
    "\n",
    "For the analysis, we will use Accuracy as a metric for performance.\n",
    "From the above graph, we see that training accuracy remains high for almost all the sigmas and it gets stable at sigma = 15. While, test accuracy starts off pretty good, it sees at sigma = 0.5 and 0.75 and then again goes up while stabling at 98.87% beyond sigma = 15.\n",
    "This maybe because for low values of sigmas, we observe little or no overlap of gaussian functions of different data points. Thus, all the centres are correctly identifying the input data which are the centres itself and hence we observe a training accuracy of almost 100%. This leads to overfitting on the training set and hence we see that for sigma = 0.5 and 0.75, the test accuracy goes down significantly.\n",
    "In the general notion, a large spread parameter implies less senstivity i.e. the kernel is more sensitive to data points that are near the centre (small sigma value) and as we go further away from centres (large sigma value) the senstivity decreases. Thus, we see a negligible decrease (around 2%) in training accuracy because the kernel function becomes less sensitive to data points but the accuracy remains pretty high as the centres are the data points itself and thus they classify the data points pretty accurately. The test accuracy seems to increase and then become stable after sigma = 15.\n",
    "Looking at the test accuracies, we will choose sigma = 15. The testing accuracy remains stable after this point. Choosing sigma = 15 ensures that value of sigma is neither too high nor too low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sCdaHAVwA9Z9"
   },
   "source": [
    "# 2a). Using Random 150 Nodes as Centres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zzRvX-N-5twy"
   },
   "outputs": [],
   "source": [
    "train_set_list = list(train_set)\n",
    "centres_list = random.choices(train_set_list, k=150)\n",
    "centres = np.array(centres_list)\n",
    "centres.shape\n",
    "X_t = centres[:, :2]\n",
    "y_t = centres[:, 2:]\n",
    "#print(X_t.shape, y_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "XY6ydOTq_qBX",
    "outputId": "2a99bbc6-2897-4a92-b5a0-8ad0dcdbc445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  98.3\n",
      "Test Accuracy:  98.88\n",
      "Train Error: 0.19611863321444545\n",
      "Test Error: 0.1750342479570414\n"
     ]
    }
   ],
   "source": [
    "sigma = 15\n",
    "y_pred_rand, W1 = calcWeight(X_train, X_t, sigma)\n",
    "y_pred_test_rand = pred(X_test, X_t, sigma, W1)\n",
    "print(\"Train Accuracy: \", acc(y_train, y_pred_rand))  \n",
    "print(\"Test Accuracy: \", acc(y_test, y_pred_test_rand))\n",
    "mse_train_rand = mse(y_train, y_pred_rand)[0]\n",
    "mse_test_rand = mse(y_test, y_pred_test_rand)[0]\n",
    "print(\"Train Error: \" + str(mse_train_rand))\n",
    "print(\"Test Error: \" + str(mse_test_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8pEbJwBbA0cb"
   },
   "source": [
    "# 2b). Using K-Means to get 150 Centres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPTNHRGI5yxv"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clf = KMeans(n_clusters = 150)\n",
    "clf.fit(X_train)\n",
    "cent = clf.cluster_centers_\n",
    "cent.shape\n",
    "X_cent = cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "dn_k96SlX-b5",
    "outputId": "0bd2c47b-ca8c-4175-f73b-23521ce33c21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  98.3\n",
      "Test Accuracy:  98.88\n",
      "Train Error: 0.19611751738585168\n",
      "Test Error: 0.17505316171292534\n"
     ]
    }
   ],
   "source": [
    "sigma = 15\n",
    "y_pred_kmeans, W2 = calcWeight(X_train, X_cent, sigma)\n",
    "y_pred_test_kmeans = pred(X_test, X_cent, sigma, W2)\n",
    "print(\"Train Accuracy: \", acc(y_train, y_pred_kmeans))  \n",
    "print(\"Test Accuracy: \", acc(y_test, y_pred_test_kmeans))\n",
    "mse_train_kmeans = mse(y_train, y_pred_kmeans)[0]\n",
    "mse_test_kmeans = mse(y_test, y_pred_test_kmeans)[0]\n",
    "print(\"Train Error: \" + str(mse_train_kmeans))\n",
    "print(\"Test Error: \" + str(mse_test_kmeans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2AARlJ0tLnM"
   },
   "source": [
    "### Comparing Outputs from part 1 to part 2 a) and 2 b)\n",
    "\n",
    "We see that accuracies are almost identical in parts 1 and 2. In general, for a particular data, a specific number of neurons in hidden layer are enough to represent whole of the data in RBFN. In our case, the similar accuracies may be due to the fact that the number of neurons needed in the hidden cell is an arbitrary number  which can be less than 150 too which we have not explored in this analysis. But, from the findings, we can make a point that 150 nodes in the hidden layer are sufficient to map all of the data points. Thus, taking any number of nodes greater than 150 for our hidden layer will not benefit us as we will get similar accuracies as we already can map all the data through these 150 centres. The errors reported are also quite similar and we see negligible difference in the errors. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled5.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
